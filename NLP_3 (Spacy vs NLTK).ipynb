{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6858dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Spacy is Object Oriented while NLTK is string processing library\n",
    "# 2. Spacy provides most efficient algorithm for a given task while NLTK provides access to many algorithms and customizations\n",
    "# 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e9de082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43285561",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94509147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Strange loves pav bhaji of mumbai.\n",
      "Hulk loves chaat of Delhi\n"
     ]
    }
   ],
   "source": [
    "d=nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chaat of Delhi\")    #spacy is used for sentence segmentation, which creates part by full stop\n",
    "for i in d.sents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091ae5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "e=nlp('''Have the central idea in your mind and convey it right at the beginning. A lot of times the central idea is conveyed right in the first sentence. “Oceans are slowly becoming human dust-bins.”\n",
    "\n",
    "Once the statement of your main idea is out there, you will be explaining or providing validation points. This way, your main idea isn’t hanging loose. This is going to make sure how the reader is going to interpret the main idea, because of you leading them to it.\n",
    "\n",
    "This is where the writer explains the focus point. “Garbage in the ocean comes from trash from trash cans, the streets, and landfills that gets blown into sewers, rivers, or directly into the ocean. The trash makes its way into storm drains. Trash travels through sewer pipes, into waterways, and finally into the ocean.”\n",
    "\n",
    "Use an Example\n",
    "Examples always clarify without explanations. People understand better when you give them something to relate to. They provide the necessary evidence or support required to prove our central idea. “A new study – based on what researchers called a mega-expedition to the Great Pacific Garbage Patch in 2015 – suggests there is about 16 times more waste than previously thought floating there. The mass of waste spans 617,763 square miles(1.6 million square km), about three times the size of France.”\n",
    "\n",
    "Elaborate on the Example\n",
    "Connect the dots and show how the example is relevant to the central point. Always unite the furthest link to the closest idea. This idea holds every point together unified. Do not leave any of your examples unexplained. You might be able to explain the relationship between the example and the topic sentence in the same sentence which introduced the example. More often, however, you will need to explain that relationship in a separate sentence.\n",
    "\n",
    "“This plastic accumulation rate inside the Great Pacific Garbage Patch, which was greater than in the surrounding waters, indicates that the inflow of plastic into the patch continues to exceed the outflow. The fleet collected a total of 1.2 million plastic samples, while the aerial sensors scanned more than 116 square miles (300 square km) of the ocean surface.”\n",
    "\n",
    "The final always ends in a broader summarization and coalition of all points. This will also tie all the loose ends in the paragraph. The conclusion should focus on the central idea we started with. This should put focus and importance to the main theme. A lot of times, we come back to the point we literally started with at the beginning of the first paragraph in order to come full circle on our topic.\n",
    "\n",
    "If we have to put our examples now in one paragraph writing, here’s how it looks like:\n",
    "Oceans are slowly becoming human dust-bins. Garbage in the ocean comes from trash from trash cans, the streets, and landfills that gets blown into sewers, rivers, or directly into the ocean. The trash makes its way into storm drains. Trash travels through sewer pipes, into waterways, and finally into the ocean. A new study – based on what researchers called a mega-expedition to the Great Pacific Garbage Patch in 2015 – suggests there is about 16 times more waste than previously thought floating there. The mass of waste spans 617,763 square miles(1.6 million square km), about three times the size of France. This plastic accumulation rate inside the Great Pacific Garbage Patch, which was greater than in the surrounding waters, indicates that the inflow of plastic into the patch continues to exceed the outflow. The fleet collected a total of 1.2 million plastic samples, while the aerial sensors scanned more than 116 square miles (300 square km) of the ocean surface. `The need of the hour is to focus on waste management and keeping our oceans clean.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d7ffc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have the central idea in your mind and convey it right at the beginning.\n",
      "A lot of times the central idea is conveyed right in the first sentence.\n",
      "“Oceans are slowly becoming human dust-bins.”\n",
      "\n",
      "\n",
      "Once the statement of your main idea is out there, you will be explaining or providing validation points.\n",
      "This way, your main idea isn’t hanging loose.\n",
      "This is going to make sure how the reader is going to interpret the main idea, because of you leading them to it.\n",
      "\n",
      "\n",
      "This is where the writer explains the focus point.\n",
      "“Garbage in the ocean comes from trash from trash cans, the streets, and landfills that gets blown into sewers, rivers, or directly into the ocean.\n",
      "The trash makes its way into storm drains.\n",
      "Trash travels through sewer pipes, into waterways, and finally into the ocean.”\n",
      "\n",
      "\n",
      "Use an Example\n",
      "Examples always clarify without explanations.\n",
      "People understand better when you give them something to relate to.\n",
      "They provide the necessary evidence or support required to prove our central idea.\n",
      "“A new study – based on what researchers called a mega-expedition to the Great Pacific Garbage Patch in 2015 – suggests there is about 16 times more waste than previously thought floating there.\n",
      "The mass of waste spans 617,763 square miles(1.6 million square km), about three times the size of France.”\n",
      "\n",
      "\n",
      "Elaborate on the Example\n",
      "Connect the dots and show how the example is relevant to the central point.\n",
      "Always unite the furthest link to the closest idea.\n",
      "This idea holds every point together unified.\n",
      "Do not leave any of your examples unexplained.\n",
      "You might be able to explain the relationship between the example and the topic sentence in the same sentence which introduced the example.\n",
      "More often, however, you will need to explain that relationship in a separate sentence.\n",
      "\n",
      "\n",
      "“This plastic accumulation rate inside the Great Pacific Garbage Patch, which was greater than in the surrounding waters, indicates that the inflow of plastic into the patch continues to exceed the outflow.\n",
      "The fleet collected a total of 1.2 million plastic samples, while the aerial sensors scanned more than 116 square miles (300 square km) of the ocean surface.”\n",
      "\n",
      "\n",
      "The final always ends in a broader summarization and coalition of all points.\n",
      "This will also tie all the loose ends in the paragraph.\n",
      "The conclusion should focus on the central idea we started with.\n",
      "This should put focus and importance to the main theme.\n",
      "A lot of times, we come back to the point we literally started with at the beginning of the first paragraph in order to come full circle on our topic.\n",
      "\n",
      "\n",
      "If we have to put our examples now in one paragraph writing, here’s how it looks like:\n",
      "Oceans are slowly becoming human dust-bins.\n",
      "Garbage in the ocean comes from trash from trash cans, the streets, and landfills that gets blown into sewers, rivers, or directly into the ocean.\n",
      "The trash makes its way into storm drains.\n",
      "Trash travels through sewer pipes, into waterways, and finally into the ocean.\n",
      "A new study – based on what researchers called a mega-expedition to the Great Pacific Garbage Patch in 2015 – suggests there is about 16 times more waste than previously thought floating there.\n",
      "The mass of waste spans 617,763 square miles(1.6 million square km), about three times the size of France.\n",
      "This plastic accumulation rate inside the Great Pacific Garbage Patch, which was greater than in the surrounding waters, indicates that the inflow of plastic into the patch continues to exceed the outflow.\n",
      "The fleet collected a total of 1.2 million plastic samples, while the aerial sensors scanned more than 116 square miles (300 square km) of the ocean surface.\n",
      "`The need of the hour is to focus on waste management and keeping our oceans clean.\n"
     ]
    }
   ],
   "source": [
    "for i in e.sents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9897d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`\n",
      "The\n",
      "need\n",
      "of\n",
      "the\n",
      "hour\n",
      "is\n",
      "to\n",
      "focus\n",
      "on\n",
      "waste\n",
      "management\n",
      "and\n",
      "keeping\n",
      "our\n",
      "oceans\n",
      "clean\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for words in i:\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e598aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b56b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Kale\n",
      "[nltk_data]     Ji\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c89a83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826e6143",
   "metadata": {},
   "outputs": [],
   "source": [
    "C=sent_tokenize(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chaat of Delhi\")   # NLTK will segment sentence to many sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e9c0ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dr.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d54ac9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Strange loves pav bhaji of mumbai.', 'Hulk loves chaat of Delhi')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[1],C[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eecf033a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28090542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Strange loves pav bhaji of mumbai.\n",
      "Hulk loves chaat of Delhi\n"
     ]
    }
   ],
   "source": [
    "l=nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chaat of Delhi\")\n",
    "for i in l.sents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84bafe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have\n",
      "the\n",
      "central\n",
      "idea\n",
      "in\n",
      "your\n",
      "mind\n",
      "and\n",
      "convey\n",
      "it\n",
      "right\n",
      "at\n",
      "the\n",
      "beginning\n",
      ".\n",
      "A\n",
      "lot\n",
      "of\n",
      "times\n",
      "the\n",
      "central\n",
      "idea\n",
      "is\n",
      "conveyed\n",
      "right\n",
      "in\n",
      "the\n",
      "first\n",
      "sentence\n",
      ".\n",
      "“\n",
      "Oceans\n",
      "are\n",
      "slowly\n",
      "becoming\n",
      "human\n",
      "dust\n",
      "-\n",
      "bins\n",
      ".\n",
      "”\n",
      "\n",
      "\n",
      "\n",
      "Once\n",
      "the\n",
      "statement\n",
      "of\n",
      "your\n",
      "main\n",
      "idea\n",
      "is\n",
      "out\n",
      "there\n",
      ",\n",
      "you\n",
      "will\n",
      "be\n",
      "explaining\n",
      "or\n",
      "providing\n",
      "validation\n",
      "points\n",
      ".\n",
      "This\n",
      "way\n",
      ",\n",
      "your\n",
      "main\n",
      "idea\n",
      "is\n",
      "n’t\n",
      "hanging\n",
      "loose\n",
      ".\n",
      "This\n",
      "is\n",
      "going\n",
      "to\n",
      "make\n",
      "sure\n",
      "how\n",
      "the\n",
      "reader\n",
      "is\n",
      "going\n",
      "to\n",
      "interpret\n",
      "the\n",
      "main\n",
      "idea\n",
      ",\n",
      "because\n",
      "of\n",
      "you\n",
      "leading\n",
      "them\n",
      "to\n",
      "it\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "This\n",
      "is\n",
      "where\n",
      "the\n",
      "writer\n",
      "explains\n",
      "the\n",
      "focus\n",
      "point\n",
      ".\n",
      "“\n",
      "Garbage\n",
      "in\n",
      "the\n",
      "ocean\n",
      "comes\n",
      "from\n",
      "trash\n",
      "from\n",
      "trash\n",
      "cans\n",
      ",\n",
      "the\n",
      "streets\n",
      ",\n",
      "and\n",
      "landfills\n",
      "that\n",
      "gets\n",
      "blown\n",
      "into\n",
      "sewers\n",
      ",\n",
      "rivers\n",
      ",\n",
      "or\n",
      "directly\n",
      "into\n",
      "the\n",
      "ocean\n",
      ".\n",
      "The\n",
      "trash\n",
      "makes\n",
      "its\n",
      "way\n",
      "into\n",
      "storm\n",
      "drains\n",
      ".\n",
      "Trash\n",
      "travels\n",
      "through\n",
      "sewer\n",
      "pipes\n",
      ",\n",
      "into\n",
      "waterways\n",
      ",\n",
      "and\n",
      "finally\n",
      "into\n",
      "the\n",
      "ocean\n",
      ".\n",
      "”\n",
      "\n",
      "\n",
      "\n",
      "Use\n",
      "an\n",
      "Example\n",
      "\n",
      "\n",
      "Examples\n",
      "always\n",
      "clarify\n",
      "without\n",
      "explanations\n",
      ".\n",
      "People\n",
      "understand\n",
      "better\n",
      "when\n",
      "you\n",
      "give\n",
      "them\n",
      "something\n",
      "to\n",
      "relate\n",
      "to\n",
      ".\n",
      "They\n",
      "provide\n",
      "the\n",
      "necessary\n",
      "evidence\n",
      "or\n",
      "support\n",
      "required\n",
      "to\n",
      "prove\n",
      "our\n",
      "central\n",
      "idea\n",
      ".\n",
      "“\n",
      "A\n",
      "new\n",
      "study\n",
      "–\n",
      "based\n",
      "on\n",
      "what\n",
      "researchers\n",
      "called\n",
      "a\n",
      "mega\n",
      "-\n",
      "expedition\n",
      "to\n",
      "the\n",
      "Great\n",
      "Pacific\n",
      "Garbage\n",
      "Patch\n",
      "in\n",
      "2015\n",
      "–\n",
      "suggests\n",
      "there\n",
      "is\n",
      "about\n",
      "16\n",
      "times\n",
      "more\n",
      "waste\n",
      "than\n",
      "previously\n",
      "thought\n",
      "floating\n",
      "there\n",
      ".\n",
      "The\n",
      "mass\n",
      "of\n",
      "waste\n",
      "spans\n",
      "617,763\n",
      "square\n",
      "miles(1.6\n",
      "million\n",
      "square\n",
      "km\n",
      ")\n",
      ",\n",
      "about\n",
      "three\n",
      "times\n",
      "the\n",
      "size\n",
      "of\n",
      "France\n",
      ".\n",
      "”\n",
      "\n",
      "\n",
      "\n",
      "Elaborate\n",
      "on\n",
      "the\n",
      "Example\n",
      "\n",
      "\n",
      "Connect\n",
      "the\n",
      "dots\n",
      "and\n",
      "show\n",
      "how\n",
      "the\n",
      "example\n",
      "is\n",
      "relevant\n",
      "to\n",
      "the\n",
      "central\n",
      "point\n",
      ".\n",
      "Always\n",
      "unite\n",
      "the\n",
      "furthest\n",
      "link\n",
      "to\n",
      "the\n",
      "closest\n",
      "idea\n",
      ".\n",
      "This\n",
      "idea\n",
      "holds\n",
      "every\n",
      "point\n",
      "together\n",
      "unified\n",
      ".\n",
      "Do\n",
      "not\n",
      "leave\n",
      "any\n",
      "of\n",
      "your\n",
      "examples\n",
      "unexplained\n",
      ".\n",
      "You\n",
      "might\n",
      "be\n",
      "able\n",
      "to\n",
      "explain\n",
      "the\n",
      "relationship\n",
      "between\n",
      "the\n",
      "example\n",
      "and\n",
      "the\n",
      "topic\n",
      "sentence\n",
      "in\n",
      "the\n",
      "same\n",
      "sentence\n",
      "which\n",
      "introduced\n",
      "the\n",
      "example\n",
      ".\n",
      "More\n",
      "often\n",
      ",\n",
      "however\n",
      ",\n",
      "you\n",
      "will\n",
      "need\n",
      "to\n",
      "explain\n",
      "that\n",
      "relationship\n",
      "in\n",
      "a\n",
      "separate\n",
      "sentence\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "“\n",
      "This\n",
      "plastic\n",
      "accumulation\n",
      "rate\n",
      "inside\n",
      "the\n",
      "Great\n",
      "Pacific\n",
      "Garbage\n",
      "Patch\n",
      ",\n",
      "which\n",
      "was\n",
      "greater\n",
      "than\n",
      "in\n",
      "the\n",
      "surrounding\n",
      "waters\n",
      ",\n",
      "indicates\n",
      "that\n",
      "the\n",
      "inflow\n",
      "of\n",
      "plastic\n",
      "into\n",
      "the\n",
      "patch\n",
      "continues\n",
      "to\n",
      "exceed\n",
      "the\n",
      "outflow\n",
      ".\n",
      "The\n",
      "fleet\n",
      "collected\n",
      "a\n",
      "total\n",
      "of\n",
      "1.2\n",
      "million\n",
      "plastic\n",
      "samples\n",
      ",\n",
      "while\n",
      "the\n",
      "aerial\n",
      "sensors\n",
      "scanned\n",
      "more\n",
      "than\n",
      "116\n",
      "square\n",
      "miles\n",
      "(\n",
      "300\n",
      "square\n",
      "km\n",
      ")\n",
      "of\n",
      "the\n",
      "ocean\n",
      "surface\n",
      ".\n",
      "”\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "final\n",
      "always\n",
      "ends\n",
      "in\n",
      "a\n",
      "broader\n",
      "summarization\n",
      "and\n",
      "coalition\n",
      "of\n",
      "all\n",
      "points\n",
      ".\n",
      "This\n",
      "will\n",
      "also\n",
      "tie\n",
      "all\n",
      "the\n",
      "loose\n",
      "ends\n",
      "in\n",
      "the\n",
      "paragraph\n",
      ".\n",
      "The\n",
      "conclusion\n",
      "should\n",
      "focus\n",
      "on\n",
      "the\n",
      "central\n",
      "idea\n",
      "we\n",
      "started\n",
      "with\n",
      ".\n",
      "This\n",
      "should\n",
      "put\n",
      "focus\n",
      "and\n",
      "importance\n",
      "to\n",
      "the\n",
      "main\n",
      "theme\n",
      ".\n",
      "A\n",
      "lot\n",
      "of\n",
      "times\n",
      ",\n",
      "we\n",
      "come\n",
      "back\n",
      "to\n",
      "the\n",
      "point\n",
      "we\n",
      "literally\n",
      "started\n",
      "with\n",
      "at\n",
      "the\n",
      "beginning\n",
      "of\n",
      "the\n",
      "first\n",
      "paragraph\n",
      "in\n",
      "order\n",
      "to\n",
      "come\n",
      "full\n",
      "circle\n",
      "on\n",
      "our\n",
      "topic\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "If\n",
      "we\n",
      "have\n",
      "to\n",
      "put\n",
      "our\n",
      "examples\n",
      "now\n",
      "in\n",
      "one\n",
      "paragraph\n",
      "writing\n",
      ",\n",
      "here\n",
      "’s\n",
      "how\n",
      "it\n",
      "looks\n",
      "like\n",
      ":\n",
      "\n",
      "\n",
      "Oceans\n",
      "are\n",
      "slowly\n",
      "becoming\n",
      "human\n",
      "dust\n",
      "-\n",
      "bins\n",
      ".\n",
      "Garbage\n",
      "in\n",
      "the\n",
      "ocean\n",
      "comes\n",
      "from\n",
      "trash\n",
      "from\n",
      "trash\n",
      "cans\n",
      ",\n",
      "the\n",
      "streets\n",
      ",\n",
      "and\n",
      "landfills\n",
      "that\n",
      "gets\n",
      "blown\n",
      "into\n",
      "sewers\n",
      ",\n",
      "rivers\n",
      ",\n",
      "or\n",
      "directly\n",
      "into\n",
      "the\n",
      "ocean\n",
      ".\n",
      "The\n",
      "trash\n",
      "makes\n",
      "its\n",
      "way\n",
      "into\n",
      "storm\n",
      "drains\n",
      ".\n",
      "Trash\n",
      "travels\n",
      "through\n",
      "sewer\n",
      "pipes\n",
      ",\n",
      "into\n",
      "waterways\n",
      ",\n",
      "and\n",
      "finally\n",
      "into\n",
      "the\n",
      "ocean\n",
      ".\n",
      "A\n",
      "new\n",
      "study\n",
      "–\n",
      "based\n",
      "on\n",
      "what\n",
      "researchers\n",
      "called\n",
      "a\n",
      "mega\n",
      "-\n",
      "expedition\n",
      "to\n",
      "the\n",
      "Great\n",
      "Pacific\n",
      "Garbage\n",
      "Patch\n",
      "in\n",
      "2015\n",
      "–\n",
      "suggests\n",
      "there\n",
      "is\n",
      "about\n",
      "16\n",
      "times\n",
      "more\n",
      "waste\n",
      "than\n",
      "previously\n",
      "thought\n",
      "floating\n",
      "there\n",
      ".\n",
      "The\n",
      "mass\n",
      "of\n",
      "waste\n",
      "spans\n",
      "617,763\n",
      "square\n",
      "miles(1.6\n",
      "million\n",
      "square\n",
      "km\n",
      ")\n",
      ",\n",
      "about\n",
      "three\n",
      "times\n",
      "the\n",
      "size\n",
      "of\n",
      "France\n",
      ".\n",
      "This\n",
      "plastic\n",
      "accumulation\n",
      "rate\n",
      "inside\n",
      "the\n",
      "Great\n",
      "Pacific\n",
      "Garbage\n",
      "Patch\n",
      ",\n",
      "which\n",
      "was\n",
      "greater\n",
      "than\n",
      "in\n",
      "the\n",
      "surrounding\n",
      "waters\n",
      ",\n",
      "indicates\n",
      "that\n",
      "the\n",
      "inflow\n",
      "of\n",
      "plastic\n",
      "into\n",
      "the\n",
      "patch\n",
      "continues\n",
      "to\n",
      "exceed\n",
      "the\n",
      "outflow\n",
      ".\n",
      "The\n",
      "fleet\n",
      "collected\n",
      "a\n",
      "total\n",
      "of\n",
      "1.2\n",
      "million\n",
      "plastic\n",
      "samples\n",
      ",\n",
      "while\n",
      "the\n",
      "aerial\n",
      "sensors\n",
      "scanned\n",
      "more\n",
      "than\n",
      "116\n",
      "square\n",
      "miles\n",
      "(\n",
      "300\n",
      "square\n",
      "km\n",
      ")\n",
      "of\n",
      "the\n",
      "ocean\n",
      "surface\n",
      ".\n",
      "`\n",
      "The\n",
      "need\n",
      "of\n",
      "the\n",
      "hour\n",
      "is\n",
      "to\n",
      "focus\n",
      "on\n",
      "waste\n",
      "management\n",
      "and\n",
      "keeping\n",
      "our\n",
      "oceans\n",
      "clean\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in e:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efa9c8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=e[0]\n",
    "dir(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bce71f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_bulk_merge',\n",
       " '_context',\n",
       " '_get_array_attrs',\n",
       " '_realloc',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'cats',\n",
       " 'char_span',\n",
       " 'copy',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'extend_tensor',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'from_dict',\n",
       " 'from_disk',\n",
       " 'from_docs',\n",
       " 'from_json',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_annotation',\n",
       " 'has_extension',\n",
       " 'has_unknown_spaces',\n",
       " 'has_vector',\n",
       " 'is_nered',\n",
       " 'is_parsed',\n",
       " 'is_sentenced',\n",
       " 'is_tagged',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'remove_extension',\n",
       " 'retokenize',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_ents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'spans',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'to_dict',\n",
       " 'to_disk',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abc26cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kale Ji\\AppData\\Local\\Temp\\ipykernel_5676\\3056328930.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  e.similarity(d)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.53620302989174"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.similarity(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cac40df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb, non-3rd person singular present'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(r.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30675364",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sent_tokenize('''Have the central idea in your mind and convey it right at the beginning. A lot of times the central idea is conveyed right in the first sentence. “Oceans are slowly becoming human dust-bins.”\n",
    "\n",
    "Once the statement of your main idea is out there, you will be explaining or providing validation points. This way, your main idea isn’t hanging loose. This is going to make sure how the reader is going to interpret the main idea, because of you leading them to it.\n",
    "\n",
    "This is where the writer explains the focus point. “Garbage in the ocean comes from trash from trash cans, the streets, and landfills that gets blown into sewers, rivers, or directly into the ocean. The trash makes its way into storm drains. Trash travels through sewer pipes, into waterways, and finally into the ocean.”\n",
    "\n",
    "Use an Example\n",
    "Examples always clarify without explanations. People understand better when you give them something to relate to. They provide the necessary evidence or support required to prove our central idea. “A new study – based on what researchers called a mega-expedition to the Great Pacific Garbage Patch in 2015 – suggests there is about 16 times more waste than previously thought floating there. The mass of waste spans 617,763 square miles(1.6 million square km), about three times the size of France.”\n",
    "\n",
    "Elaborate on the Example\n",
    "Connect the dots and show how the example is relevant to the central point. Always unite the furthest link to the closest idea. This idea holds every point together unified. Do not leave any of your examples unexplained. You might be able to explain the relationship between the example and the topic sentence in the same sentence which introduced the example. More often, however, you will need to explain that relationship in a separate sentence.\n",
    "\n",
    "“This plastic accumulation rate inside the Great Pacific Garbage Patch, which was greater than in the surrounding waters, indicates that the inflow of plastic into the patch continues to exceed the outflow. The fleet collected a total of 1.2 million plastic samples, while the aerial sensors scanned more than 116 square miles (300 square km) of the ocean surface.”\n",
    "\n",
    "The final always ends in a broader summarization and coalition of all points. This will also tie all the loose ends in the paragraph. The conclusion should focus on the central idea we started with. This should put focus and importance to the main theme. A lot of times, we come back to the point we literally started with at the beginning of the first paragraph in order to come full circle on our topic.\n",
    "\n",
    "If we have to put our examples now in one paragraph writing, here’s how it looks like:\n",
    "Oceans are slowly becoming human dust-bins. Garbage in the ocean comes from trash from trash cans, the streets, and landfills that gets blown into sewers, rivers, or directly into the ocean. The trash makes its way into storm drains. Trash travels through sewer pipes, into waterways, and finally into the ocean. A new study – based on what researchers called a mega-expedition to the Great Pacific Garbage Patch in 2015 – suggests there is about 16 times more waste than previously thought floating there. The mass of waste spans 617,763 square miles(1.6 million square km), about three times the size of France. This plastic accumulation rate inside the Great Pacific Garbage Patch, which was greater than in the surrounding waters, indicates that the inflow of plastic into the patch continues to exceed the outflow. The fleet collected a total of 1.2 million plastic samples, while the aerial sensors scanned more than 116 square miles (300 square km) of the ocean surface. `The need of the hour is to focus on waste management and keeping our oceans clean.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fb3450d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7968840b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Have the central idea in your mind and convey it right at the beginning.',\n",
       " 'A lot of times the central idea is conveyed right in the first sentence.',\n",
       " '“Oceans are slowly becoming human dust-bins.”\\n\\nOnce the statement of your main idea is out there, you will be explaining or providing validation points.',\n",
       " 'This way, your main idea isn’t hanging loose.',\n",
       " 'This is going to make sure how the reader is going to interpret the main idea, because of you leading them to it.',\n",
       " 'This is where the writer explains the focus point.',\n",
       " '“Garbage in the ocean comes from trash from trash cans, the streets, and landfills that gets blown into sewers, rivers, or directly into the ocean.',\n",
       " 'The trash makes its way into storm drains.',\n",
       " 'Trash travels through sewer pipes, into waterways, and finally into the ocean.”\\n\\nUse an Example\\nExamples always clarify without explanations.',\n",
       " 'People understand better when you give them something to relate to.',\n",
       " 'They provide the necessary evidence or support required to prove our central idea.')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[0],g[1],g[2],g[3],g[4],g[5],g[6],g[7],g[8],g[9],g[10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
